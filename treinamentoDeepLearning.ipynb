{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando o ambiente\n",
    "Bibliotecas e inicializações necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lhlag\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "    .format(user=os.environ['DB_USER'],\n",
    "            host=os.environ['DB_HOST'],\n",
    "            pw=os.environ['DB_PASSWORD'],\n",
    "            db=os.environ['DB_DATABASE']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento dos dados\n",
    "Nesse primeiro passo é feito o carregamento das ações que vamos usar para treinar a ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro carregar os dados relativos as entradas que vamos treinar a ia\n",
    "\n",
    "# Nesse software foi escolhido para treinar a ia usando ações do setor elétrico\n",
    "\n",
    "\n",
    "\n",
    "acoes = [\n",
    "    \"AESB3\",\n",
    "    \"ALUP11\",\n",
    "    \"COCE5\",\n",
    "    \"CMIG4\",\n",
    "    \"CPLE6\",\n",
    "    \"CPFE3\",\n",
    "    \"ELET3\",\n",
    "    \"ENBR3\",\n",
    "    \"ENGI11\",\n",
    "    \"ENEV3\",\n",
    "    \"EGIE3\",\n",
    "    \"EQTL3\",\n",
    "    \"LIGT3\",\n",
    "    \"NEOE3\",\n",
    "    \"MEGA3\",\n",
    "    \"TAEE11\",\n",
    "    \"TRPL4\",\n",
    "]\n",
    "\n",
    "dados_acoes = pd.read_sql('SELECT * FROM acao_historico_inputs WHERE stock_name IN (\\''+'\\',\\''.join(acoes)+'\\')',con=engine)\n",
    "\n",
    "dados_acoes.drop('id',inplace=True,axis=1)\n",
    "dados_acoes.drop('stock_name',inplace=True,axis=1)\n",
    "dados_acoes.drop('trading_date',inplace=True,axis=1)\n",
    "dados_acoes.drop('period_variation_open',inplace=True,axis=1)\n",
    "dados_acoes.drop('period_variation_close',inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1_price_open</th>\n",
       "      <th>day1_price_min</th>\n",
       "      <th>day1_price_max</th>\n",
       "      <th>day1_price_avg</th>\n",
       "      <th>day1_price_close</th>\n",
       "      <th>day2_price_open</th>\n",
       "      <th>day2_price_min</th>\n",
       "      <th>day2_price_max</th>\n",
       "      <th>day2_price_avg</th>\n",
       "      <th>day2_price_close</th>\n",
       "      <th>...</th>\n",
       "      <th>day9_price_min</th>\n",
       "      <th>day9_price_max</th>\n",
       "      <th>day9_price_avg</th>\n",
       "      <th>day9_price_close</th>\n",
       "      <th>global_price_open</th>\n",
       "      <th>global_price_min</th>\n",
       "      <th>global_price_max</th>\n",
       "      <th>global_price_avg</th>\n",
       "      <th>global_price_close</th>\n",
       "      <th>period_variation_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.94</td>\n",
       "      <td>15.62</td>\n",
       "      <td>15.65</td>\n",
       "      <td>15.70</td>\n",
       "      <td>15.62</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.94</td>\n",
       "      <td>15.98</td>\n",
       "      <td>16.01</td>\n",
       "      <td>15.94</td>\n",
       "      <td>...</td>\n",
       "      <td>16.90</td>\n",
       "      <td>16.93</td>\n",
       "      <td>17.01</td>\n",
       "      <td>16.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.62</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.60</td>\n",
       "      <td>15.77</td>\n",
       "      <td>15.80</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.77</td>\n",
       "      <td>15.94</td>\n",
       "      <td>15.62</td>\n",
       "      <td>15.65</td>\n",
       "      <td>15.70</td>\n",
       "      <td>15.62</td>\n",
       "      <td>...</td>\n",
       "      <td>17.67</td>\n",
       "      <td>17.69</td>\n",
       "      <td>17.41</td>\n",
       "      <td>17.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.53</td>\n",
       "      <td>16.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.84</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.53</td>\n",
       "      <td>15.66</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.60</td>\n",
       "      <td>15.77</td>\n",
       "      <td>15.80</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.77</td>\n",
       "      <td>...</td>\n",
       "      <td>17.40</td>\n",
       "      <td>17.50</td>\n",
       "      <td>17.50</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.49</td>\n",
       "      <td>15.51</td>\n",
       "      <td>16.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.52</td>\n",
       "      <td>15.49</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.52</td>\n",
       "      <td>15.49</td>\n",
       "      <td>15.84</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.53</td>\n",
       "      <td>15.66</td>\n",
       "      <td>15.51</td>\n",
       "      <td>...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.03</td>\n",
       "      <td>17.04</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.35</td>\n",
       "      <td>15.36</td>\n",
       "      <td>16.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.58</td>\n",
       "      <td>15.35</td>\n",
       "      <td>15.36</td>\n",
       "      <td>15.46</td>\n",
       "      <td>15.35</td>\n",
       "      <td>15.52</td>\n",
       "      <td>15.49</td>\n",
       "      <td>15.51</td>\n",
       "      <td>15.52</td>\n",
       "      <td>15.49</td>\n",
       "      <td>...</td>\n",
       "      <td>16.75</td>\n",
       "      <td>16.80</td>\n",
       "      <td>16.84</td>\n",
       "      <td>16.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.35</td>\n",
       "      <td>15.85</td>\n",
       "      <td>16.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23405</th>\n",
       "      <td>23.25</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.31</td>\n",
       "      <td>23.28</td>\n",
       "      <td>23.31</td>\n",
       "      <td>23.18</td>\n",
       "      <td>23.25</td>\n",
       "      <td>23.26</td>\n",
       "      <td>23.29</td>\n",
       "      <td>23.25</td>\n",
       "      <td>...</td>\n",
       "      <td>23.26</td>\n",
       "      <td>23.28</td>\n",
       "      <td>23.33</td>\n",
       "      <td>23.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.41</td>\n",
       "      <td>23.13</td>\n",
       "      <td>43.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23406</th>\n",
       "      <td>23.12</td>\n",
       "      <td>23.08</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.11</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.25</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.31</td>\n",
       "      <td>23.28</td>\n",
       "      <td>23.31</td>\n",
       "      <td>...</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.94</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.41</td>\n",
       "      <td>22.89</td>\n",
       "      <td>43.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23407</th>\n",
       "      <td>23.12</td>\n",
       "      <td>22.88</td>\n",
       "      <td>22.89</td>\n",
       "      <td>22.88</td>\n",
       "      <td>22.89</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.08</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.11</td>\n",
       "      <td>23.13</td>\n",
       "      <td>...</td>\n",
       "      <td>22.71</td>\n",
       "      <td>22.74</td>\n",
       "      <td>22.75</td>\n",
       "      <td>22.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.41</td>\n",
       "      <td>22.91</td>\n",
       "      <td>43.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23408</th>\n",
       "      <td>22.95</td>\n",
       "      <td>22.89</td>\n",
       "      <td>22.91</td>\n",
       "      <td>22.94</td>\n",
       "      <td>22.91</td>\n",
       "      <td>23.12</td>\n",
       "      <td>22.88</td>\n",
       "      <td>22.89</td>\n",
       "      <td>22.88</td>\n",
       "      <td>22.89</td>\n",
       "      <td>...</td>\n",
       "      <td>22.91</td>\n",
       "      <td>22.92</td>\n",
       "      <td>22.71</td>\n",
       "      <td>22.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.41</td>\n",
       "      <td>22.89</td>\n",
       "      <td>43.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23409</th>\n",
       "      <td>22.95</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.89</td>\n",
       "      <td>22.86</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.95</td>\n",
       "      <td>22.89</td>\n",
       "      <td>22.91</td>\n",
       "      <td>22.94</td>\n",
       "      <td>22.91</td>\n",
       "      <td>...</td>\n",
       "      <td>23.24</td>\n",
       "      <td>23.32</td>\n",
       "      <td>23.30</td>\n",
       "      <td>23.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.41</td>\n",
       "      <td>22.92</td>\n",
       "      <td>43.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23410 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       day1_price_open  day1_price_min  day1_price_max  day1_price_avg  \\\n",
       "0                15.94           15.62           15.65           15.70   \n",
       "1                15.60           15.77           15.80           15.87   \n",
       "2                15.84           15.51           15.53           15.66   \n",
       "3                15.52           15.49           15.51           15.52   \n",
       "4                15.58           15.35           15.36           15.46   \n",
       "...                ...             ...             ...             ...   \n",
       "23405            23.25           23.30           23.31           23.28   \n",
       "23406            23.12           23.08           23.13           23.11   \n",
       "23407            23.12           22.88           22.89           22.88   \n",
       "23408            22.95           22.89           22.91           22.94   \n",
       "23409            22.95           22.85           22.89           22.86   \n",
       "\n",
       "       day1_price_close  day2_price_open  day2_price_min  day2_price_max  \\\n",
       "0                 15.62            16.20           15.94           15.98   \n",
       "1                 15.77            15.94           15.62           15.65   \n",
       "2                 15.51            15.60           15.77           15.80   \n",
       "3                 15.49            15.84           15.51           15.53   \n",
       "4                 15.35            15.52           15.49           15.51   \n",
       "...                 ...              ...             ...             ...   \n",
       "23405             23.31            23.18           23.25           23.26   \n",
       "23406             23.13            23.25           23.30           23.31   \n",
       "23407             22.89            23.12           23.08           23.13   \n",
       "23408             22.91            23.12           22.88           22.89   \n",
       "23409             22.85            22.95           22.89           22.91   \n",
       "\n",
       "       day2_price_avg  day2_price_close  ...  day9_price_min  day9_price_max  \\\n",
       "0               16.01             15.94  ...           16.90           16.93   \n",
       "1               15.70             15.62  ...           17.67           17.69   \n",
       "2               15.87             15.77  ...           17.40           17.50   \n",
       "3               15.66             15.51  ...           17.00           17.03   \n",
       "4               15.52             15.49  ...           16.75           16.80   \n",
       "...               ...               ...  ...             ...             ...   \n",
       "23405           23.29             23.25  ...           23.26           23.28   \n",
       "23406           23.28             23.31  ...           22.85           22.86   \n",
       "23407           23.11             23.13  ...           22.71           22.74   \n",
       "23408           22.88             22.89  ...           22.91           22.92   \n",
       "23409           22.94             22.91  ...           23.24           23.32   \n",
       "\n",
       "       day9_price_avg  day9_price_close  global_price_open  global_price_min  \\\n",
       "0               17.01             16.92                0.0             15.62   \n",
       "1               17.41             17.69                0.0             15.51   \n",
       "2               17.50             17.40                0.0             15.49   \n",
       "3               17.04             17.00                0.0             15.35   \n",
       "4               16.84             16.75                0.0             15.35   \n",
       "...               ...               ...                ...               ...   \n",
       "23405           23.33             23.28                0.0             17.41   \n",
       "23406           22.94             22.86                0.0             17.41   \n",
       "23407           22.75             22.74                0.0             17.41   \n",
       "23408           22.71             22.92                0.0             17.41   \n",
       "23409           23.30             23.24                0.0             17.41   \n",
       "\n",
       "       global_price_max  global_price_avg  global_price_close  \\\n",
       "0                 15.80             16.62                 0.0   \n",
       "1                 15.53             16.54                 0.0   \n",
       "2                 15.51             16.45                 0.0   \n",
       "3                 15.36             16.38                 0.0   \n",
       "4                 15.85             16.32                 0.0   \n",
       "...                 ...               ...                 ...   \n",
       "23405             23.13             43.67                 0.0   \n",
       "23406             22.89             43.66                 0.0   \n",
       "23407             22.91             43.64                 0.0   \n",
       "23408             22.89             43.63                 0.0   \n",
       "23409             22.92             43.62                 0.0   \n",
       "\n",
       "       period_variation_avg  \n",
       "0                     -0.25  \n",
       "1                     -2.21  \n",
       "2                     -1.28  \n",
       "3                      0.84  \n",
       "4                      2.59  \n",
       "...                     ...  \n",
       "23405                 -1.72  \n",
       "23406                 -0.74  \n",
       "23407                 -0.09  \n",
       "23408                  0.00  \n",
       "23409                  0.44  \n",
       "\n",
       "[23410 rows x 51 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_acoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dados_acoes['period_variation_avg'].tolist()\n",
    "X = dados_acoes.drop('period_variation_avg',axis=1).values.tolist()\n",
    "\n",
    "\n",
    "'''\n",
    "    0 - se for menor de -3%\n",
    "    1 - se for menor que -1.5%\n",
    "    2 - se for menor que -0.5%\n",
    "    3 - se for menor que 0.5%\n",
    "    4 - se for menor que 1.5%\n",
    "    5 - se for menor que 3%\n",
    "'''\n",
    "\n",
    "separator = [-3,-1.5,-0.5,0.5,1.5,3,float('inf')]\n",
    "a = np.array([0,1,2,3,4,5,6])\n",
    "for idx,y_t in enumerate(Y):\n",
    "    index = next(x[0] for x in enumerate(separator) if x[1] > y_t)\n",
    "    Y[idx]= (a==index).astype('float')\n",
    "\n",
    "for idx,x_t in enumerate(X):\n",
    "    X[idx] = np.reshape(x_t,(10,5))\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embaralhamento e Separação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_shuffle(X, Y, perc = 0.1):\n",
    "  ''' Esta função embaralha os pares de entradas\n",
    "      e saídas desejadas, e separa os dados de\n",
    "      treinamento e validação\n",
    "  '''\n",
    "  # Total de amostras\n",
    "  tot = len(X)\n",
    "  # Emabaralhamento dos índices\n",
    "  indexes = np.arange(tot)\n",
    "  np.random.shuffle(indexes)\n",
    "  # Calculo da quantidade de amostras de\n",
    "  # treinamento\n",
    "  n = int((1 - perc)*tot)\n",
    "  Xt = X[indexes[:n]]\n",
    "  Yt = Y[indexes[:n]]\n",
    "  Xv = X[indexes[n:]]\n",
    "  Yv = Y[indexes[n:]]\n",
    "  return Xt, Yt, Xv, Yv\n",
    "\n",
    "Xt,Yt,Xv,Yv = split_and_shuffle(X,Y,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.from_numpy(Xt)\n",
    "Yt = torch.from_numpy(Yt)\n",
    "Xv = torch.from_numpy(Xv)\n",
    "Yv = torch.from_numpy(Yv)\n",
    "\n",
    "Xt = Xt.unsqueeze(1)\n",
    "Xv = Xv.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treinamento:\n",
      "Xt torch.Size([19898, 1, 10, 5]) Yt torch.Size([19898, 7])\n",
      "\n",
      "Dados de validação:\n",
      "Xv torch.Size([3512, 1, 10, 5]) Yv torch.Size([3512, 7])\n"
     ]
    }
   ],
   "source": [
    "print('Dados de treinamento:')\n",
    "print('Xt', Xt.size(), 'Yt', Yt.size())\n",
    "print()\n",
    "print('Dados de validação:')\n",
    "print('Xv', Xv.size(), 'Yv', Yv.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeção da Rede Neural\n",
    "\n",
    "1.   `conv1`: Camada convolucional com kernel 3x1, 3 canais de saída, sem padding, stride 1 e ativação ReLU.\n",
    "2.   `pool1`: Camada _max-pooling_ 3x1, com stride 1.\n",
    "3.   `conv2`: Camada convolucional com kernel 3x2, 5 canais de saída, sem padding, stride 1 e ativação ReLU.\n",
    "4.   `drop1`: Dropout 10%.\n",
    "5.   `lin1`: Camada feedforward que recebe os dados serializados e gera as saídas. A função de ativação final é _softmax_, mas ela é implementada no cálculo da função de custo, então não precisa ser considerada aqui.\n",
    "\n",
    "N1 = 3\n",
    "\n",
    "N2a = 8\n",
    "\n",
    "N2b = 5\n",
    "\n",
    "N3 = 3 * 8 * 5\n",
    "\n",
    "N4 = 3\n",
    "\n",
    "N5a = 6\n",
    "\n",
    "N5b = 5\n",
    "\n",
    "N6 = 3 * 6 * 5\n",
    "\n",
    "N7 = 5\n",
    "\n",
    "N8a = 4\n",
    "\n",
    "N8b = 4\n",
    "\n",
    "N9 = 5 * 4 * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=(3,1),stride=1) \n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d((3,1), stride=1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(3, 5, kernel_size=(3,2),stride=1)\n",
    "\n",
    "        self.drp1 = nn.Dropout2d(0.1)\n",
    "        \n",
    "        self.lin1 = nn.Linear(80, 7)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.drp1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(-1, 80)\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(3, 1), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=(3, 1), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(3, 5, kernel_size=(3, 2), stride=(1, 1))\n",
      "  (drp1): Dropout2d(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=80, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(neural,x, y_hat):\n",
    "  y = neural(x).argmax(dim=1)\n",
    "  y_hat = y_hat.argmax(dim=1)\n",
    "  return 100*float((y == y_hat).sum()) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(cnn.parameters(), lr=0.0001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cnn = cnn.to(gpu)\n",
    "Xt = Xt.to(gpu, dtype=torch.float)\n",
    "Yt = Yt.to(gpu, dtype=torch.long)\n",
    "Xv = Xv.to(gpu, dtype=torch.float)\n",
    "Yv = Yv.to(gpu, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() missing 1 required positional argument: 'y_hat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mb:\\Python\\Projeto B3\\treinamentoDeepLearning.ipynb Célula: 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/b%3A/Python/Projeto%20B3/treinamentoDeepLearning.ipynb#ch0000029?line=32'>33</a>\u001b[0m \u001b[39m# A cada 200 épocas imprimimos o\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/b%3A/Python/Projeto%20B3/treinamentoDeepLearning.ipynb#ch0000029?line=33'>34</a>\u001b[0m \u001b[39m# erro do último lote e a acurácia\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/b%3A/Python/Projeto%20B3/treinamentoDeepLearning.ipynb#ch0000029?line=34'>35</a>\u001b[0m \u001b[39m# nos dados de treinamento\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/b%3A/Python/Projeto%20B3/treinamentoDeepLearning.ipynb#ch0000029?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (j \u001b[39m%\u001b[39m \u001b[39m200\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/b%3A/Python/Projeto%20B3/treinamentoDeepLearning.ipynb#ch0000029?line=36'>37</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mfloat\u001b[39m(e), evaluate(Xt, Yt))\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate() missing 1 required positional argument: 'y_hat'"
     ]
    }
   ],
   "source": [
    "for j in range(2001):\n",
    "\n",
    "  # Faremos o treinamento em lotes de\n",
    "  # tamanho igual a 128 amostras\n",
    "  for i in range(0,len(Yt),128):\n",
    "\n",
    "    # Separa o lote de entradas\n",
    "    x = Xt[i:i+128,:,:,:]\n",
    "\n",
    "    # Separa o lote de saídas desejadas\n",
    "    # já transformando de one-hot para\n",
    "    # índice das colunas.\n",
    "    y_hat = Yt[i:i+128,:].argmax(dim=1)\n",
    "\n",
    "    # Zera o gradiente do otimizador\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # Calcula a saída da rede neural\n",
    "    y = cnn(x)\n",
    "\n",
    "    # Calcula o erro\n",
    "    e = loss(y, y_hat)\n",
    "\n",
    "    # Calcula o gradiente usando\n",
    "    # backpropagation\n",
    "    e.backward()\n",
    "\n",
    "    # Realiza um passo de atualização\n",
    "    # dos parâmetros da rede neural\n",
    "    # usando o otimizador.\n",
    "    opt.step()\n",
    "\n",
    "  # A cada 200 épocas imprimimos o\n",
    "  # erro do último lote e a acurácia\n",
    "  # nos dados de treinamento\n",
    "  if not (j % 200):\n",
    "    print(float(e), evaluate(cnn,Xt, Yt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37732729c0781a435259e9861159cca5ef8c5c39d29c217566ff5da3de2d4cca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
